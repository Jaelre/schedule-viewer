# Telemetry Deep-Dive

This document explains how the telemetry client and Worker endpoint cooperate to
emit usage events. It supplements the high-level summary in the
[README](../README.md#telemetry) and provides operational notes for tuning,
storage, and verification.

## Event schema

Each browser event is enqueued as a JSON object with the following structure:

```json
{
  "name": "shift_grid.view",
  "timestamp": "2025-01-18T09:15:32.904Z",
  "sequence": 17,
  "context": {
    "ym": "2025-02",
    "density": "compact"
  },
  "user": {
    "id": "33935",
    "role": "clinician"
  },
  "device": {
    "locale": "it-IT",
    "viewport": {
      "width": 1440,
      "height": 900
    }
  }
}
```

- `name` *(string)* – Stable identifier for the action being logged.
- `timestamp` *(ISO 8601 string)* – When the event was generated in the browser.
- `sequence` *(number)* – Monotonic counter generated by the client helper so the
  Worker can reason about ordering inside a batch.
- `context` *(object)* – Arbitrary payload describing feature-level state. Keep
  keys snake_case and values serialisable as JSON.
- `user` *(object)* – Optional user metadata; redact direct identifiers unless
  the downstream storage is already protected.
- `device` *(object)* – Snapshot of device details (locale, viewport, user agent
  fragment). This block is optional to keep payloads lightweight.

## Batching and flush thresholds

The client helper appends events to an in-memory queue and evaluates the
following flush conditions:

| Trigger | Description | Config | Default |
| --- | --- | --- | --- |
| Batch size | Flush when the queue reaches the batch limit. | `TELEMETRY_MAX_BATCH_SIZE` (Worker) | 20 |
| Interval | Flush on a cadence even if the queue is not full. | `TELEMETRY_FLUSH_INTERVAL_MS` (Worker) | 5000 ms |
| Page lifecycle | Flush immediately when the document is hidden, the tab closes, or the browser fires `beforeunload`. | n/a | Always on |

The Worker returns HTTP 202 upon successful ingestion. Non-2xx responses leave
the queue intact and the helper retries on the next interval tick so that short
outages do not drop data.

## Storage and logging destinations

Incoming batches are handled by the Worker route at `/api/telemetry`:

1. Requests must include the same `Authorization: Bearer <token>` header issued
   by `/api/access`; unauthenticated requests are rejected with 401.
2. When `TELEMETRY_LOG_ONLY=true` (default), the Worker writes each event to
   structured logs (visible via `wrangler tail` or Cloudflare Dashboard) and
   returns immediately without persisting to R2.
3. When `TELEMETRY_LOG_ONLY=false` and the `TELEMETRY_BUCKET` R2 binding is
   configured, batches are persisted to R2 with one object per flush. Objects
   are stored under `<yyyymmdd>/<uuid>.jsonl` so they can be processed later
   with analytics tooling.

No raw telemetry is stored in the browser; once the flush promise resolves the
queue is cleared.

### R2 bucket configuration

To enable R2 storage for telemetry:

1. Create the R2 buckets (one-time setup):
   ```bash
   wrangler r2 bucket create schedule-viewer-telemetry
   wrangler r2 bucket create schedule-viewer-telemetry-preview
   ```

2. The buckets are already configured in `wrangler.toml` with binding `TELEMETRY_BUCKET`.

3. Set `TELEMETRY_LOG_ONLY=false` in `wrangler.toml` (or leave as default for log-only mode).

4. Deploy the worker:
   ```bash
   cd worker && wrangler deploy
   ```

## Inspecting telemetry output

Use the following approaches to confirm telemetry delivery end-to-end:

- **Local development** – Run `cd worker && wrangler dev` and inspect console
  output; the Worker always prints a summary when flushing events. Full event
  payloads are logged when `TELEMETRY_LOG_ONLY=true`.
- **Tail production traffic** – Execute `wrangler tail` to stream structured
  logs from the live Worker in real-time.
- **Cloudflare Dashboard** – View logs in the Cloudflare dashboard under your
  Worker's "Logs" tab for historical access.
- **Review persisted batches** – If R2 storage is enabled
  (`TELEMETRY_LOG_ONLY=false`), list objects with
  `wrangler r2 object list schedule-viewer-telemetry` and download the relevant
  JSONL files for offline analysis:
  ```bash
  # List all telemetry files
  wrangler r2 object list schedule-viewer-telemetry

  # Download a specific file
  wrangler r2 object get schedule-viewer-telemetry/<yyyymmdd>/<uuid>.jsonl --file telemetry.jsonl
  ```

Refer back to [docs/access-gate.md](access-gate.md#telemetry-and-token-reuse)
for guidance on reusing the access gate token and rotating credentials.
